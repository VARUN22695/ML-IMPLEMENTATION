# -*- coding: utf-8 -*-
"""anamoly_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IxmP04_CVkVyeLOQhKKp7Zx8DBAIF-1k
"""

2+7

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min

# Step 1: Generate and Visualize Data
np.random.seed(42)
cluster_1 = np.random.randn(50, 2) + np.array([5, 5])
cluster_2 = np.random.randn(50, 2) + np.array([-5, -5])
cluster_3 = np.random.randn(50, 2) + np.array([-5, 5])
outliers = np.array([[15, 15], [-15, -15], [15, -15], [-15, 15]])
data = np.concatenate([cluster_1, cluster_2, cluster_3, outliers])

plt.scatter(data[:, 0], data[:, 1], s=30)
plt.title("Data with Clusters and Outliers")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 2: Apply K-Means Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(data)
data_clusters = kmeans.predict(data)
centroids = kmeans.cluster_centers_

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75, marker='X')
plt.title("K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 3: Compute Distances to Cluster Centroids
_, distances = pairwise_distances_argmin_min(data, centroids)

plt.hist(distances, bins=30, alpha=0.7)
plt.title("Histogram of Distances to Nearest Centroid")
plt.xlabel("Distance to Nearest Centroid")
plt.ylabel("Frequency")
plt.show()

# Step 4: Identify Anomalies
threshold = np.percentile(distances, 95)
anomalies = data[distances > threshold]

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=100, alpha=0.75, marker='X')
plt.title("Anomalies Detected by K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

print("Anomalies detected:\n", anomalies)





print(len(cluster_1 ))
print(len(cluster_2 ))
print(len(cluster_3 ))
print(len(outliers))

np.random.randint(2,50)

np.array([5, 5])

np.random.randn(2,3)

np.random.randn(2,3)

np.random.randn(2, 3) + np.array([3, 3])[:, None]

l=[1,7,9,4,0,15,17,18,12,6,8,11]
 np.percentile(l, 100)

l.sort()

l

sum([9>=i for i in l])

(7/len(l))*100

x=np.random.randn(3, 2)
print(x)
y=np.random.randn(3, 2)
print(y)

np.concatenate([x,y])

np.concatenate([x,y]).shape

data.shape

data

plt.scatter(data[:, 0], data[:, 1], s=30)

_, distances = pairwise_distances_argmin_min(data, centroids)

distances

plt.title("Histogram of Distances to Nearest Centroid")

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min

# Step 1: Generate and Visualize Data
np.random.seed(42)
cluster_1 = np.random.randn(50, 2) + np.array([5, 5])
cluster_2 = np.random.randn(50, 2) + np.array([-5, -5])
cluster_3 = np.random.randn(50, 2) + np.array([-5, 5])
outliers = np.array([[15, 15], [-15, -15], [15, -15], [-15, 15]])
data = np.concatenate([cluster_1, cluster_2, cluster_3, outliers])

plt.scatter(data[:, 0], data[:, 1], s=30)
plt.title("Data with Clusters and Outliers")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 2: Apply K-Means Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(data)
data_clusters = kmeans.predict(data)
centroids = kmeans.cluster_centers_

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75, marker='X')
plt.title("K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 3: Compute Distances to Cluster Centroids
_, distances = pairwise_distances_argmin_min(data, centroids)

plt.hist(distances, bins=30, alpha=0.7)
plt.title("Histogram of Distances to Nearest Centroid")
plt.xlabel("Distance to Nearest Centroid")
plt.ylabel("Frequency")
plt.show()

# Step 4: Identify Anomalies
threshold = np.percentile(distances, 95)
anomalies = data[distances > threshold]

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=100, alpha=0.75, marker='X')
plt.title("Anomalies Detected by K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

print("Anomalies detected:\n", anomalies)

np.random.randint(1, 11, size=(3, 2))

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min

# Step 1: Generate and Visualize Data
np.random.seed(42)
cluster_1 =  np.random.randint(1, 11, size=(3, 2))
cluster_2 =  np.random.randint(1, 11, size=(3, 2))
cluster_3 =  np.random.randint(1, 11, size=(3, 2))
outliers = np.array([[15, 15], [-15, -15], [15, -15], [-15, 15]])
data = np.concatenate([cluster_1, cluster_2, cluster_3, outliers])

plt.scatter(data[:, 0], data[:, 1], s=30)
plt.title("Data with Clusters and Outliers")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 2: Apply K-Means Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(data)
data_clusters = kmeans.predict(data)
centroids = kmeans.cluster_centers_

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75, marker='X')
plt.title("K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 3: Compute Distances to Cluster Centroids
_, distances = pairwise_distances_argmin_min(data, centroids)

plt.hist(distances, bins=30, alpha=0.7)
plt.title("Histogram of Distances to Nearest Centroid")
plt.xlabel("Distance to Nearest Centroid")
plt.ylabel("Frequency")
plt.show()

# Step 4: Identify Anomalies
threshold = np.percentile(distances, 95)
anomalies = data[distances > threshold]

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=100, alpha=0.75, marker='X')
plt.title("Anomalies Detected by K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

print("Anomalies detected:\n", anomalies)

data

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min

# Step 1: Generate and Visualize Data
data = np.array([16,17,20,21,28,30,42,50,62,65,70,85,100,120]).reshape(-1, 1)

# Step 2: Apply K-Means Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(data)
data_clusters = kmeans.predict(data)
centroids = kmeans.cluster_centers_

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75, marker='X')
plt.title("K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 3: Compute Distances to Cluster Centroids
_, distances = pairwise_distances_argmin_min(data, centroids)

plt.hist(distances, bins=30, alpha=0.7)
plt.title("Histogram of Distances to Nearest Centroid")
plt.xlabel("Distance to Nearest Centroid")
plt.ylabel("Frequency")
plt.show()

# Step 4: Identify Anomalies
threshold = np.percentile(distances, 95)
anomalies = data[distances > threshold]

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=100, alpha=0.75, marker='X')
plt.title("Anomalies Detected by K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

print("Anomalies detected:\n", anomalies)

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min

# Step 1: Generate and Visualize Data


# Step 2: Apply K-Means Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(data)
data_clusters = kmeans.predict(data)
centroids = kmeans.cluster_centers_


# Step 3: Compute Distances to Cluster Centroids
_, distances = pairwise_distances_argmin_min(data, centroids)

plt.hist(distances, bins=30, alpha=0.7)
plt.title("Histogram of Distances to Nearest Centroid")
plt.xlabel("Distance to Nearest Centroid")
plt.ylabel("Frequency")
plt.show()

# Step 4: Identify Anomalies
threshold = np.percentile(distances, 95)
anomalies = data[distances > threshold]

plt.scatter(data[:, 0], data[:, 1], c=data_clusters, s=30, cmap='viridis')
plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=100, alpha=0.75, marker='X')
plt.title("Anomalies Detected by K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

print("Anomalies detected:\n", anomalies)

import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# List of values (including an outlier)
values = [16,17,20,21,28,30,42,50,62,65,70,85,100,120]

# Convert the list into a 2D array for K-Means clustering
data = np.array(values).reshape(-1, 1)

# Apply K-Means with K=2
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(data)

# Assign clusters
data_clusters = kmeans.predict(data)
centroids = kmeans.cluster_centers_

# Calculate the distance to the nearest centroid
distances = np.linalg.norm(data - centroids[data_clusters], axis=1)

# Set a threshold for anomaly detection (95th percentile)
threshold = np.percentile(distances, 95)

# Identify anomalies
anomalies = data[distances > threshold]

# Print the results
print("Original Data:")
print(values)
print("\nCluster centroids:")
print(centroids)
print("\nCluster assignments:")
print(data_clusters)
print("\nDistances to nearest centroids:")
print(distances)
print(f"\nAnomalies detected (values with distances > {threshold}):")
print(anomalies)

# Optional: Plot the data, centroids, and anomalies
plt.scatter(data, np.zeros_like(data), c=data_clusters, cmap='viridis', s=50, marker='o', label='Data points')
plt.scatter(centroids, np.zeros_like(centroids), c='red', s=200, alpha=0.75, marker='X', label='Centroids')
plt.scatter(anomalies, np.zeros_like(anomalies), c='red', s=100, alpha=0.75, marker='x', label='Anomalies')
plt.legend()
plt.title("Anomaly Detection with K-Means Clustering")
plt.xlabel("Values")
plt.show()

l

np.percentile(l,95)

distances

x=data[distances>27]
print(x)